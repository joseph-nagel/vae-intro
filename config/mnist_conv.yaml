seed_everything: null

ckpt_path: null

data:
  class_path: "varautoenc.MNISTDataModule"
  init_args:
    data_dir: "run/data"
    binarize_threshold: null
    mean: null
    std: null
    batch_size: 32
    num_workers: 0

model:
  class_path: "varautoenc.ConvVAE"
  init_args:
    num_channels: [1, 32, 64]
    num_features: [3136, 512, 64]
    reshape: [64, 7, 7]
    kernel_size: 3
    pooling: 2
    upsample_mode: "bilinear"
    activation: "leaky_relu"
    last_activation: null
    batchnorm: false
    drop_rate: null
    pool_last: true
    double_conv: true
    beta: 1.0
    num_samples: 1
    likelihood_type: "Bernoulli"
    sigma: null
    per_channel: false
    lr: 0.0001
    lr_schedule: "constant"
    lr_interval: "epoch"
    lr_warmup: 0

trainer:
  accelerator: "cpu"
  max_epochs: 100
  log_every_n_steps: 100
  logger:
    class_path: "lightning.pytorch.loggers.TensorBoardLogger"
    init_args:
      save_dir: "run/"
      name: "mnist_conv"
      version: null
    # class_path: "lightning.pytorch.loggers.MLFlowLogger"
    # init_args:
    #   experiment_name: "mnist_conv"
    #   run_name: null
    #   save_dir: "run/mlruns"
    #   log_model: true
  callbacks:
    - class_path: "lightning.pytorch.callbacks.LearningRateMonitor"
      init_args:
        logging_interval: null
    - class_path: "lightning.pytorch.callbacks.ModelCheckpoint"
      init_args:
        filename: "best"
        monitor: "val_loss"
        mode: "min"
        save_top_k: 1
    - class_path: "lightning.pytorch.callbacks.ModelCheckpoint"
      init_args:
        filename: "{epoch}"
        save_top_k: -1
        every_n_epochs: 2
        save_last: true
    # - class_path: "lightning.pytorch.callbacks.ModelCheckpoint"
    #   init_args:
    #     filename: "{step}"
    #     save_top_k: -1
    #     every_n_train_steps: 100
    #     save_last: false

