seed_everything: null

ckpt_path: null

data:
  class_path: "varautoenc.MNISTDataModule"
  init_args:
    data_dir: "run/data"
    binarize_threshold: null
    mean: null
    std: null
    batch_size: 32
    num_workers: 0

model:
  class_path: "varautoenc.DenseVAE"
  init_args:
    num_features: [784, 512, 128, 32, 2]
    reshape: [1, 28, 28]
    activation: "leaky_relu"
    batchnorm: false
    drop_rate: null
    beta: 1.0
    num_samples: 1
    likelihood_type: "Bernoulli"
    sigma: null
    per_feature: false
    lr: 0.0001
    lr_schedule: "constant"
    lr_interval: "epoch"
    lr_warmup: 0

trainer:
  accelerator: "cpu"
  max_epochs: 50
  log_every_n_steps: 100
  logger:
    class_path: "lightning.pytorch.loggers.TensorBoardLogger"
    init_args:
      save_dir: "run/"
      name: "mnist_dense"
      version: null
    # class_path: "lightning.pytorch.loggers.MLFlowLogger"
    # init_args:
    #   experiment_name: "mnist_dense"
    #   run_name: null
    #   save_dir: "run/mlruns"
    #   log_model: true
  callbacks:
    - class_path: "lightning.pytorch.callbacks.LearningRateMonitor"
      init_args:
        logging_interval: null
    - class_path: "lightning.pytorch.callbacks.ModelCheckpoint"
      init_args:
        filename: "best"
        monitor: "val_loss"
        mode: "min"
        save_top_k: 1
    - class_path: "lightning.pytorch.callbacks.ModelCheckpoint"
      init_args:
        filename: "{epoch}"
        save_top_k: -1
        every_n_epochs: 2
        save_last: true
    - class_path: "lightning.pytorch.callbacks.ModelCheckpoint"
      init_args:
        filename: "{step}"
        save_top_k: -1
        every_n_train_steps: 100
        save_last: false
