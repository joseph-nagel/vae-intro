seed_everything: null

ckpt_path: null

data:
  class_path: "varautoenc.CIFAR10DataModule"
  init_args:
    data_dir: "run/data"
    mean: [0.5, 0.5, 0.5]
    std: [0.5, 0.5, 0.5]
    batch_size: 32
    num_workers: 0

model:
  class_path: "varautoenc.ConvVAE"
  init_args:
    num_channels: [3, 16, 32]
    num_features: [2048, 512, 128]
    reshape: [32, 8, 8]
    kernel_size: 3
    pooling: 2
    upsample_mode: "bilinear"
    activation: "leaky_relu"
    last_activation: null
    batchnorm: false
    drop_rate: null
    pool_last: true
    double_conv: true
    beta: 1.0
    num_samples: 1
    likelihood_type: "Gaussian"
    sigma: null
    per_channel: false
    lr: 0.0001

trainer:
  accelerator: "gpu"
  max_epochs: 100
  log_every_n_steps: 100
  logger:
    class_path: "lightning.pytorch.loggers.TensorBoardLogger"
    init_args:
      save_dir: "run/"
      name: "cifar10"
      version: null
    # class_path: "lightning.pytorch.loggers.MLFlowLogger"
    # init_args:
    #   experiment_name: "cifar10"
    #   run_name: null
    #   save_dir: "run/mlruns"
    #   log_model: true
  callbacks:
    - class_path: "lightning.pytorch.callbacks.LearningRateMonitor"
      init_args:
        logging_interval: null
    - class_path: "lightning.pytorch.callbacks.ModelCheckpoint"
      init_args:
        filename: "best"
        monitor: "val_loss"
        mode: "min"
        save_top_k: 1
    - class_path: "lightning.pytorch.callbacks.ModelCheckpoint"
      init_args:
        filename: "{epoch}"
        save_top_k: -1
        every_n_epochs: 2
        save_last: true
    # - class_path: "lightning.pytorch.callbacks.ModelCheckpoint"
    #   init_args:
    #     filename: "{step}"
    #     save_top_k: -1
    #     every_n_train_steps: 100
    #     save_last: false

